{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data & Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"../1/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
       "0         0         0         1         0         1         0         0  ...    \n",
       "1         0         0         1         0         1         0         0  ...    \n",
       "2         0         0         1         1         1         0         0  ...    \n",
       "3         0         0         1         1         1         0         0  ...    \n",
       "4         0         0         1         0         1         0         0  ...    \n",
       "\n",
       "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         1         0         0         1         0         0         0   \n",
       "2         1         0         0         0         1         0         0   \n",
       "3         1         0         0         0         1         0         0   \n",
       "4         1         0         0         0         0         0         0   \n",
       "\n",
       "   feat_255  feat_256   gap  \n",
       "0         0         0  1.19  \n",
       "1         0         0  1.60  \n",
       "2         0         0  1.49  \n",
       "3         0         0  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191c0e2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#first do some exploratory data analysis, and we find that \n",
    "#the distribution of gap is quite symmetric.\n",
    "plt.hist(df_train['gap'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             smiles  feat_001  feat_002  \\\n",
       "0   1  c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...         0         0   \n",
       "1   2         [nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1         0         0   \n",
       "2   3  [nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...         1         0   \n",
       "3   4  [nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...         1         0   \n",
       "4   5  c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008    ...     \\\n",
       "0         0         0         1         1         1         0    ...      \n",
       "1         0         0         1         1         1         0    ...      \n",
       "2         0         0         1         1         1         0    ...      \n",
       "3         0         0         1         1         1         0    ...      \n",
       "4         0         0         1         0         1         0    ...      \n",
       "\n",
       "   feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   feat_254  feat_255  feat_256  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../1/data/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store gap values\n",
    "Y_train = df_train.gap.values\n",
    "#row where testing examples start\n",
    "test_idx = df_train.shape[0]\n",
    "#delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "#delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \\\n",
       "0         0         0         1         0         1         0         0   \n",
       "1         0         0         1         0         1         0         0   \n",
       "2         0         0         1         1         1         0         0   \n",
       "3         0         0         1         1         1         0         0   \n",
       "4         0         0         1         0         1         0         0   \n",
       "\n",
       "     ...     feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  \\\n",
       "0    ...            0         1         0         0         0         0   \n",
       "1    ...            0         1         0         0         1         0   \n",
       "2    ...            0         1         0         0         0         1   \n",
       "3    ...            0         1         0         0         0         1   \n",
       "4    ...            0         1         0         0         0         0   \n",
       "\n",
       "   feat_253  feat_254  feat_255  feat_256  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame with all train and test examples so we can more easily apply feature engineering on\n",
    "df_all = pd.concat((df_train, df_test), axis=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example Feature Engineering\n",
    "\n",
    "this calculates the length of each smile string and adds a feature column with those lengths\n",
    "Note: this is NOT a good feature and will result in a lower score!\n",
    "\"\"\"\n",
    "length = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "df_all['carbon'] = df_all['smiles'].apply(lambda r: r.count('c') + r.count('C'))\n",
    "df_all['oxygen'] = df_all['smiles'].apply(lambda r: r.count('o'))\n",
    "df_all['nitrogen'] = df_all['smiles'].apply(lambda r: r.count('n'))\n",
    "df_all['sulfur'] = df_all['smiles'].apply(lambda r: r.count('s'))\n",
    "df_all['hydrogen'] = df_all['smiles'].apply(lambda r: r.count('H'))\n",
    "df_all['[]'] = df_all['smiles'].apply(lambda r: r.count('['))\n",
    "df_all['()'] = df_all['smiles'].apply(lambda r: r.count('('))\n",
    "df_all['onelink']=df_all['smiles'].apply(lambda r: r.count('-'))\n",
    "df_all['doublelink']=df_all['smiles'].apply(lambda r: r.count('='))\n",
    "df_all['1']=df_all['smiles'].apply(lambda r: r.count('1'))\n",
    "df_all['2']=df_all['smiles'].apply(lambda r: r.count('2'))\n",
    "df_all['3']=df_all['smiles'].apply(lambda r: r.count('3'))\n",
    "df_all['4']=df_all['smiles'].apply(lambda r: r.count('4'))\n",
    "df_all['5']=df_all['smiles'].apply(lambda r: r.count('5'))\n",
    "df_all['6']=df_all['smiles'].apply(lambda r: r.count('6'))\n",
    "df_all['p_carbon'] = df_all['smiles'].apply(lambda r: (r.count('c') + r.count('C'))/len(r))\n",
    "df_all['p_oxygen'] = df_all['smiles'].apply(lambda r: r.count('o')/len(r))\n",
    "df_all['p_nitrogen'] = df_all['smiles'].apply(lambda r: r.count('n')/len(r))\n",
    "df_all['p_sulfur'] = df_all['smiles'].apply(lambda r: r.count('s')/len(r))\n",
    "df_all['p_hydrogen'] = df_all['smiles'].apply(lambda r: r.count('H')/len(r))\n",
    "df_all['p_[]'] = df_all['smiles'].apply(lambda r: r.count('[')/len(r))\n",
    "df_all['p_()'] = df_all['smiles'].apply(lambda r: r.count('(')/len(r))\n",
    "df_all['p_onelink']=df_all['smiles'].apply(lambda r: r.count('-')/len(r))\n",
    "df_all['p_doublelink']=df_all['smiles'].apply(lambda r: r.count('=')/len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>p_carbon</th>\n",
       "      <th>p_oxygen</th>\n",
       "      <th>p_nitrogen</th>\n",
       "      <th>p_sulfur</th>\n",
       "      <th>p_hydrogen</th>\n",
       "      <th>p_[]</th>\n",
       "      <th>p_()</th>\n",
       "      <th>p_onelink</th>\n",
       "      <th>p_doublelink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \\\n",
       "0         0         0         1         0         1         0         0   \n",
       "1         0         0         1         0         1         0         0   \n",
       "2         0         0         1         1         1         0         0   \n",
       "3         0         0         1         1         1         0         0   \n",
       "4         0         0         1         0         1         0         0   \n",
       "\n",
       "       ...       6  p_carbon  p_oxygen  p_nitrogen  p_sulfur  p_hydrogen  \\\n",
       "0      ...       0         0         0           0         0           0   \n",
       "1      ...       0         0         0           0         0           0   \n",
       "2      ...       0         0         0           0         0           0   \n",
       "3      ...       0         0         0           0         0           0   \n",
       "4      ...       0         0         0           0         0           0   \n",
       "\n",
       "   p_[]  p_()  p_onelink  p_doublelink  \n",
       "0     0     0          0             0  \n",
       "1     0     0          0             0  \n",
       "2     0     0          0             0  \n",
       "3     0     0          0             0  \n",
       "4     0     0          0             0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 280)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 280)\n"
     ]
    }
   ],
   "source": [
    "#Drop the 'smiles' column\n",
    "df_all = df_all.drop(['smiles'], axis=1)\n",
    "lcols = df_all.columns.values.tolist()\n",
    "vals = df_all.values\n",
    "X_train = vals[:test_idx]\n",
    "X_test = vals[test_idx:]\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "print \"The Random Forest Regressor MSE is %0.4f\" %RF.score(X_train,Y_train)\n",
    "RF_pred = RF.predict(X_train)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_pred_test = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_pred_test.shape\n",
    "write_to_file(\"RF-chemical.csv\", RF_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 1.0000\n",
      "Train data MSE is  4.01332376259e-29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.4f\" %LR.score(X_train,Y_train)\n",
    "LR_pred = LR.predict(X_train)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Regressor MSE is 0.5542\n",
      "Train data MSE is  0.0739172340539\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "print \"The Random Forest Regressor MSE is %0.4f\" %RF.score(X_train,Y_train)\n",
    "RF_pred = RF.predict(X_train)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.76081465e-01   1.59972425e-01   1.15301757e-01   8.90472885e-02\n",
      "   7.40744684e-02   4.92047246e-02   4.40554673e-02   3.63085238e-02\n",
      "   3.21632895e-02   2.26566731e-02   1.92636921e-02   1.41765412e-02\n",
      "   8.93850942e-03   8.65251544e-03   6.47451957e-03   4.72463112e-03\n",
      "   4.35919750e-03   3.94628535e-03   3.69395853e-03   3.48938200e-03\n",
      "   3.11493820e-03   2.74259107e-03   2.59550503e-03   2.41449257e-03\n",
      "   1.92857343e-03   1.64479114e-03   1.50181240e-03   1.15086407e-03\n",
      "   1.09598034e-03   1.03249368e-03   8.60642578e-04   7.46830375e-04\n",
      "   6.54927007e-04   6.26435715e-04   4.26062217e-04   2.90293188e-04\n",
      "   2.71942157e-04   1.33252205e-04   1.04085415e-04   4.41414199e-05\n",
      "   3.30775083e-05   5.88036648e-07   3.66686051e-07   4.23886864e-30\n",
      "   5.44474685e-32   1.13116818e-32   3.93338679e-33   2.41759273e-33\n",
      "   1.02471034e-33   1.02471034e-33]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train, Y_train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "pca_components = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train[:5000], Y_train[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.4610\n",
      "Train data MSE is  0.0893565916881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train_pca, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.4f\" %LR.score(X_train_pca,Y_train)\n",
    "LR_pred = LR.predict(X_train_pca)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Regressor MSE is 0.5542\n",
      "Train data MSE is  0.0739171315696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensamble.RandomForestRegressor\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train_pca, Y_train)\n",
    "\n",
    "print \"The Random Forest Regressor MSE is %0.4f\" %RF.score(X_train_pca,Y_train)\n",
    "RF_pred = RF.predict(X_train_pca)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emsemble Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'do_regress' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-fd7c0cd3480f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ridge, Xtrain, ytrain, Xtest, ytest = do_regress(RF, {\"n_estimators\": [10, 20, 50]},\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                  X_train_pca, Y_train,mask=mask,score_func=\"mean_squared_error\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'do_regress' is not defined"
     ]
    }
   ],
   "source": [
    "RF = RandomForestRegressor(n_jobs = -1)\n",
    "ridge, Xtrain, ytrain, Xtest, ytest = do_regress(RF, {\"n_estimators\": [10, 20, 50]},\n",
    "                                                 X_train_pca, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Regressor MSE is 0.9628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "AB = AdaBoostRegressor(RandomForestRegressor(n_estimators=50))\n",
    "AB.fit(X_train_pca, Y_train[:5000])\n",
    "print \"The Random Forest Regressor MSE is %0.4f\" %AB.score(X_train_pca,Y_train[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AB_pred = AB.predict(X_train_pca)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,AB_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"AB_pred.csv\", AB_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf,parameters,X,y,n_folds,score_func=None):\n",
    "    if score_func:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    fitmodel.fit(X,y)\n",
    "    print \"BEST\", fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_\n",
    "    best = fitmodel.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_regress(clf, parameters,X,y,mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    \n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.5f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.5f\" % (test_accuracy)\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonzero(clf):\n",
    "    featuremask=(clf.coef_ !=0.0)\n",
    "    return pd.DataFrame(dict(feature=lcols, coef=clf.coef_, abscoef=np.abs(clf.coef_)))[featuremask].sort('abscoef', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha': 10.0} -0.0892598130548 [mean: -0.08926, std: 0.00041, params: {'alpha': 0.001}, mean: -0.08926, std: 0.00041, params: {'alpha': 0.01}, mean: -0.08926, std: 0.00041, params: {'alpha': 0.1}, mean: -0.08926, std: 0.00041, params: {'alpha': 1.0}, mean: -0.08926, std: 0.00041, params: {'alpha': 10.0}, mean: -0.08927, std: 0.00041, params: {'alpha': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.46157\n",
      "Accuracy on test data:     0.45976\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "ridge, Xtrain, ytrain, Xtest, ytest = do_regress(Ridge(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train_pca, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(X_train_pca.shape[0]), train_size=0.7)\n",
    "mask=np.ones(X_train_pca.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "lasso, Xtrain, ytrain, Xtest, ytest = do_regress(Lasso(), \\\n",
    "                                                   {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\\\n",
    "                                                   X_train,Y_train,mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent - SGDÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha': 1e-06} -0.0894535074507 [mean: -0.08945, std: 0.00039, params: {'alpha': 1e-06}, mean: -0.08949, std: 0.00042, params: {'alpha': 0.001}, mean: -0.09060, std: 0.00040, params: {'alpha': 0.01}, mean: -0.10038, std: 0.00043, params: {'alpha': 0.1}, mean: -0.13701, std: 0.00037, params: {'alpha': 1.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.46081\n",
      "Accuracy on test data:     0.46072\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "SGD = linear_model.SGDRegressor()\n",
    "SGD, Xtrain, ytrain, Xtest, ytest = do_regress(SGD, {\"alpha\": [1e-6, 0.001, 0.01, 0.1, 1.0]},\n",
    "                                                    X_train_pca, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha_2': 1.0, 'alpha_1': 1e-06} -0.0893432903939 [mean: -0.08934, std: 0.00041, params: {'alpha_2': 1e-06, 'alpha_1': 1e-06}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.001, 'alpha_1': 1e-06}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.01, 'alpha_1': 1e-06}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.1, 'alpha_1': 1e-06}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1.0, 'alpha_1': 1e-06}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1e-06, 'alpha_1': 0.001}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.001, 'alpha_1': 0.001}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.01, 'alpha_1': 0.001}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.1, 'alpha_1': 0.001}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1.0, 'alpha_1': 0.001}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1e-06, 'alpha_1': 0.01}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.001, 'alpha_1': 0.01}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.01, 'alpha_1': 0.01}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.1, 'alpha_1': 0.01}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1.0, 'alpha_1': 0.01}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1e-06, 'alpha_1': 0.1}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.001, 'alpha_1': 0.1}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.01, 'alpha_1': 0.1}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.1, 'alpha_1': 0.1}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1.0, 'alpha_1': 0.1}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1e-06, 'alpha_1': 1.0}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.001, 'alpha_1': 1.0}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.01, 'alpha_1': 1.0}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 0.1, 'alpha_1': 1.0}, mean: -0.08934, std: 0.00041, params: {'alpha_2': 1.0, 'alpha_1': 1.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.46109\n",
      "Accuracy on test data:     0.46089\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "BayesianRidge = linear_model.BayesianRidge()\n",
    "BayesianRidge, Xtrain, ytrain, Xtest, ytest = do_regress(BayesianRidge, {\"alpha_1\": [1e-6, 0.001, 0.01, 0.1, 1.0], \"alpha_2\": [1e-6, 0.001, 0.01, 0.1, 1.0]},\n",
    "                                                    X_train_pca, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AB = AdaBoostRegressor(RandomForestRegressor(n_estimators=50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.4608\n",
      "Train data MSE is  0.0893973458867\n"
     ]
    }
   ],
   "source": [
    "EN = linear_model.ElasticNetCV()\n",
    "EN.fit(X_train_pca, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.4f\" %EN.score(X_train_pca,Y_train)\n",
    "EN_pred = EN.predict(X_train_pca)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,EN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.3429\n",
      "Train data MSE is  0.108934078892\n"
     ]
    }
   ],
   "source": [
    "OMP = linear_model.OrthogonalMatchingPursuit()\n",
    "OMP.fit(X_train_pca, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.4f\" %OMP.score(X_train_pca,Y_train)\n",
    "EN_pred = OMP.predict(X_train_pca)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,EN_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction Using Pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abscorr</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_005</th>\n",
       "      <td>0.363979</td>\n",
       "      <td>-0.363979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_003</th>\n",
       "      <td>0.330177</td>\n",
       "      <td>-0.330177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_007</th>\n",
       "      <td>0.318515</td>\n",
       "      <td>-0.318515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_001</th>\n",
       "      <td>0.173378</td>\n",
       "      <td>-0.173378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_009</th>\n",
       "      <td>0.170262</td>\n",
       "      <td>0.170262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_015</th>\n",
       "      <td>0.138328</td>\n",
       "      <td>0.138328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_017</th>\n",
       "      <td>0.096622</td>\n",
       "      <td>0.096622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_022</th>\n",
       "      <td>0.081951</td>\n",
       "      <td>0.081951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_014</th>\n",
       "      <td>0.070313</td>\n",
       "      <td>-0.070313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_008</th>\n",
       "      <td>0.065026</td>\n",
       "      <td>0.065026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_023</th>\n",
       "      <td>0.051795</td>\n",
       "      <td>0.051795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_018</th>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.045148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_002</th>\n",
       "      <td>0.043903</td>\n",
       "      <td>-0.043903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_012</th>\n",
       "      <td>0.043526</td>\n",
       "      <td>-0.043526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_024</th>\n",
       "      <td>0.035575</td>\n",
       "      <td>0.035575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_026</th>\n",
       "      <td>0.035253</td>\n",
       "      <td>-0.035253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_016</th>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.031225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_011</th>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.029308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_019</th>\n",
       "      <td>0.024206</td>\n",
       "      <td>-0.024206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_006</th>\n",
       "      <td>0.022990</td>\n",
       "      <td>-0.022990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_004</th>\n",
       "      <td>0.020608</td>\n",
       "      <td>-0.020608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_025</th>\n",
       "      <td>0.010668</td>\n",
       "      <td>-0.010668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_020</th>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.007969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_010</th>\n",
       "      <td>0.006093</td>\n",
       "      <td>-0.006093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_013</th>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           abscorr      corr\n",
       "feature                     \n",
       "feat_005  0.363979 -0.363979\n",
       "feat_003  0.330177 -0.330177\n",
       "feat_007  0.318515 -0.318515\n",
       "feat_001  0.173378 -0.173378\n",
       "feat_009  0.170262  0.170262\n",
       "feat_015  0.138328  0.138328\n",
       "feat_017  0.096622  0.096622\n",
       "feat_022  0.081951  0.081951\n",
       "feat_014  0.070313 -0.070313\n",
       "feat_008  0.065026  0.065026\n",
       "feat_023  0.051795  0.051795\n",
       "feat_018  0.045148  0.045148\n",
       "feat_002  0.043903 -0.043903\n",
       "feat_012  0.043526 -0.043526\n",
       "feat_024  0.035575  0.035575\n",
       "feat_026  0.035253 -0.035253\n",
       "feat_016  0.031225  0.031225\n",
       "feat_011  0.029308  0.029308\n",
       "feat_019  0.024206 -0.024206\n",
       "feat_006  0.022990 -0.022990\n",
       "feat_004  0.020608 -0.020608\n",
       "feat_025  0.010668 -0.010668\n",
       "feat_020  0.007969  0.007969\n",
       "feat_010  0.006093 -0.006093\n",
       "feat_013  0.005361  0.005361"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "correlations=[]\n",
    "for col in xrange(X_train_pca.shape[1]):\n",
    "    r=pearsonr(X_train_pca.T[col], Y_train)[0]\n",
    "    correlations.append(dict(feature=lcols[col],corr=r, abscorr=np.abs(r)))\n",
    "\n",
    "bpdf=pd.DataFrame(correlations).sort('abscorr', ascending=False)\n",
    "bpdf.set_index(['feature'], inplace=True)\n",
    "bpdf.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ridge(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " {'alpha': 10.0},\n",
       " -0.089361855421948064,\n",
       " [mean: -0.08936, std: 0.00031, params: {'alpha': 1e-06},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 1e-05},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 5e-05},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 0.0001},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 0.0005},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 0.001},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 0.01},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 0.1},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 1.0},\n",
       "  mean: -0.08936, std: 0.00031, params: {'alpha': 10.0},\n",
       "  mean: -0.08937, std: 0.00031, params: {'alpha': 100.0}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "def cv_optimize_ridge(X, y, n_folds=4):\n",
    "    clf = Ridge()\n",
    "    parameters = {\"alpha\": [1e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 1e-2, 1e-1, 1.0,10.0,100.0]}\n",
    "    #the scoring parameter below is the default one in ridge, but you can use a different one\n",
    "    #in the cross-validation phase if you want.\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=\"mean_squared_error\")\n",
    "    gs.fit(X, y)\n",
    "    return gs\n",
    "fitmodel = cv_optimize_ridge(X_train_pca, Y_train, n_folds=4)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonzero(clf):\n",
    "    featuremask=(clf.coef_ !=0.0)\n",
    "    return pd.DataFrame(dict(feature=lcols, coef=clf.coef_, abscoef=np.abs(clf.coef_)))[featuremask].sort('abscoef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4d1ce376c8be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mridge_importances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mridge_importances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mridge_importances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-4026282919e4>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeaturemask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabscoef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeaturemask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abscoef'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         return _arrays_to_mgr(arrays, data_names, index, columns,\n\u001b[0;32m--> 363\u001b[0;31m                               dtype=dtype)\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     def _init_ndarray(self, values, index, columns, dtype=None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5156\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   5204\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5206\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "ridge_importances=nonzero(fitmodel.best_estimator_)\n",
    "ridge_importances.set_index(\"feature\", inplace=True)\n",
    "ridge_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf,parameters,X,y,n_folds,score_func=None):\n",
    "    if score_func:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    fitmodel.fit(X,y)\n",
    "    print \"BEST\", fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_\n",
    "    best = fitmodel.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_regress(clf, parameters, indf, featurenames, y ,mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(X_train_pca.shape[0]), train_size=0.7)\n",
    "mask=np.ones(X_train_pca.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'alpha': 0.001} -0.09037279458 [mean: -0.09037, std: 0.00028, params: {'alpha': 0.001}, mean: -0.10039, std: 0.00021, params: {'alpha': 0.01}, mean: -0.16305, std: 0.00042, params: {'alpha': 0.1}, mean: -0.16579, std: 0.00041, params: {'alpha': 1.0}, mean: -0.16579, std: 0.00041, params: {'alpha': 10.0}, mean: -0.16579, std: 0.00041, params: {'alpha': 100.0}]\n"
     ]
    }
   ],
   "source": [
    "lasso=cv_optimize(Lasso(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, X_train_pca, Y_train, n_folds=5, score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unbound method get_params() must be called with Lasso instance as first argument (got nothing instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-eb81b32ac116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_regress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLasso\u001b[0m\u001b[0;34m,\u001b[0m                                                    \u001b[0;34m{\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m                                                   \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-44c3555deec4>\u001b[0m in \u001b[0;36mdo_regress\u001b[0;34m(clf, parameters, indf, featurenames, y, mask, reuse_split, score_func, n_folds)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-71ba1744bfc5>\u001b[0m in \u001b[0;36mcv_optimize\u001b[0;34m(clf, parameters, X, y, n_folds, score_func)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfitmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"BEST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    539\u001b[0m                                          n_candidates * len(cv)))\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     47\u001b[0m                             % (repr(estimator), type(estimator)))\n\u001b[1;32m     48\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unbound method get_params() must be called with Lasso instance as first argument (got nothing instead)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "lasso, Xtrain, ytrain, Xtest, ytest = do_regress(Lasso, \\\n",
    "                                                   {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\\\n",
    "                                                   df_train, lcols, Y_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"sample1.csv\", LR_pred)\n",
    "write_to_file(\"sample2.csv\", RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
