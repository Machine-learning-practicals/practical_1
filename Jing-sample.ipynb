{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data & Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
       "0         0         0         1         0         1         0         0  ...    \n",
       "1         0         0         1         0         1         0         0  ...    \n",
       "2         0         0         1         1         1         0         0  ...    \n",
       "3         0         0         1         1         1         0         0  ...    \n",
       "4         0         0         1         0         1         0         0  ...    \n",
       "\n",
       "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         1         0         0         1         0         0         0   \n",
       "2         1         0         0         0         1         0         0   \n",
       "3         1         0         0         0         1         0         0   \n",
       "4         1         0         0         0         0         0         0   \n",
       "\n",
       "   feat_255  feat_256   gap  \n",
       "0         0         0  1.19  \n",
       "1         0         0  1.60  \n",
       "2         0         0  1.49  \n",
       "3         0         0  1.36  \n",
       "4         0         0  1.98  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEACAYAAACtVTGuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x144358390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#first do some exploratory data analysis, and we find that \n",
    "#the distribution of gap is quite symmetric.\n",
    "plt.hist(df_train['gap'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             smiles  feat_001  feat_002  \\\n",
       "0   1  c1sc(-c2cnc3c(c2)c2nsnc2c2cc4cccnc4cc32)c2cc[n...         0         0   \n",
       "1   2         [nH]1cccc1-c1cc2c3nsnc3c3c4sccc4[nH]c3c2s1         0         0   \n",
       "2   3  [nH]1c2cc(-c3ccc[se]3)c3nsnc3c2c2c3cscc3c3ccc4...         1         0   \n",
       "3   4  [nH]1c(cc2cnc3c(c12)c1=C[SiH2]C=c1c1ccc2=CCC=c...         1         0   \n",
       "4   5  c1sc(-c2sc(-c3sc(-c4scc5[se]ccc45)c4ccoc34)c3c...         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008    ...     \\\n",
       "0         0         0         1         1         1         0    ...      \n",
       "1         0         0         1         1         1         0    ...      \n",
       "2         0         0         1         1         1         0    ...      \n",
       "3         0         0         1         1         1         0    ...      \n",
       "4         0         0         1         0         1         0    ...      \n",
       "\n",
       "   feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         0         0         0   \n",
       "3         0         1         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   feat_254  feat_255  feat_256  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store gap values\n",
    "Y_train = df_train.gap.values\n",
    "#row where testing examples start\n",
    "test_idx = df_train.shape[0]\n",
    "#delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "#delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \\\n",
       "0         0         0         1         0         1         0         0   \n",
       "1         0         0         1         0         1         0         0   \n",
       "2         0         0         1         1         1         0         0   \n",
       "3         0         0         1         1         1         0         0   \n",
       "4         0         0         1         0         1         0         0   \n",
       "\n",
       "     ...     feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  \\\n",
       "0    ...            0         1         0         0         0         0   \n",
       "1    ...            0         1         0         0         1         0   \n",
       "2    ...            0         1         0         0         0         1   \n",
       "3    ...            0         1         0         0         0         1   \n",
       "4    ...            0         1         0         0         0         0   \n",
       "\n",
       "   feat_253  feat_254  feat_255  feat_256  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFrame with all train and test examples so we can more easily apply feature engineering on\n",
    "df_all = pd.concat((df_train, df_test), axis=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>small_c</th>\n",
       "      <th>big_c</th>\n",
       "      <th>nH</th>\n",
       "      <th>SiH2</th>\n",
       "      <th>onelink</th>\n",
       "      <th>doublelink</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>se</th>\n",
       "      <th>doublelinkC</th>\n",
       "      <th>cnc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009 ...   \\\n",
       "0         0         0         1         0         1         0         0 ...    \n",
       "1         0         0         1         0         1         0         0 ...    \n",
       "2         0         0         1         1         1         0         0 ...    \n",
       "3         0         0         1         1         1         0         0 ...    \n",
       "4         0         0         1         0         1         0         0 ...    \n",
       "\n",
       "   small_c  big_c  nH  SiH2  onelink  doublelink  subgroup  se  doublelinkC  \\\n",
       "0       19      0   0     0        3           0         3   1            0   \n",
       "1       12      9   0     2        0           5         1   0            4   \n",
       "2       18      3   1     1        3           1         2   0            1   \n",
       "3       18      5   1     2        2           4         1   0            2   \n",
       "4       20      0   0     0        1           0         1   0            0   \n",
       "\n",
       "   cnc  \n",
       "0    1  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    2  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example Feature Engineering\n",
    "\n",
    "this calculates the length of each smile string and adds a feature column with those lengths\n",
    "Note: this is NOT a good feature and will result in a lower score!\n",
    "\"\"\"\n",
    "#miles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "#df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "#Number of c\n",
    "df_all['small_c']=df_all['smiles'].apply(lambda r: r.count('c'))\n",
    "df_all['big_c']=df_all['smiles'].apply(lambda r: r.count('C'))\n",
    "df_all['nH']=df_all['smiles'].apply(lambda r: r.count('[nH]'))\n",
    "df_all['SiH2']=df_all['smiles'].apply(lambda r: r.count('[SiH2]'))\n",
    "df_all['onelink']=df_all['smiles'].apply(lambda r: r.count('-'))\n",
    "df_all['doublelink']=df_all['smiles'].apply(lambda r: r.count('='))\n",
    "df_all['subgroup']=df_all['smiles'].apply(lambda r: r.count('('))\n",
    "df_all['se']=df_all['smiles'].apply(lambda r: r.count('se'))\n",
    "df_all['doublelinkC']=df_all['smiles'].apply(lambda r: r.count('=C'))\n",
    "df_all['cnc']=df_all['smiles'].apply(lambda r: r.count('cnc'))\n",
    "\n",
    "\n",
    "featAd=['small_c','big_c','nH','SiH2','onelink','doublelink','subgroup','se','cnc','doublelinkC']\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2nsnc12'\n",
      " 'C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[SiH2]C=c12'\n",
      " '[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-23)c2ccccc12'\n",
      " '[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13)c1=C[SiH2]C=c21'\n",
      " 'c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1'\n",
      " 'C1=Cc2cnc3cc4cc(-c5scc6[nH]ccc56)c5ccccc5c4cc3c2[SiH2]1'\n",
      " 'c1ncc(s1)-c1cnc2c(c1)oc1c2ccc2ccccc12'\n",
      " 'c1sc(-c2ccc3c(c2)sc2c3c3=CCC=c3c3cccnc23)c2[se]ccc12'\n",
      " 'c1ccc(o1)-c1cc2cc3cc4c5c[nH]cc5ccc4cc3cc2o1'\n",
      " '[nH]1ccc2c3c[nH]cc3c3cc(-c4cncs4)c4=CCC=c4c3c12'\n",
      " '[nH]1c(cc2c3cocc3c3c(ccc4ccc5=CCC=c5c34)c12)-c1cccs1'\n",
      " 'c1cc2oc3c(sc4cc([se]c34)-c3cncc4nsnc34)c2o1'\n",
      " '[nH]1c(cc2cnc3cc4ccoc4cc3c12)-c1ccccc1'\n",
      " '[nH]1ccc2ccc3c4ncc(cc4[nH]c3c12)-c1scc2occc12'\n",
      " 'c1sc(-c2sc(-c3sc(-c4ncncn4)c4nccnc34)c3cc[nH]c23)c2ccCc12'\n",
      " 'c1cc2ncc(cc2s1)-c1cc2c(ccc3ccccc23)c2c[nH]cc12'\n",
      " 'c1ccc(-c2cc3oc4ccc5c[nH]cc5c4c3cn2)c2cscc12'\n",
      " '[nH]1c2-c3ncc(cc3Cc2c2[se]ccc12)-c1scc2ccoc12'\n",
      " 'c1cnc(s1)-c1ccc(cc1)-c1sc(c2Cccc12)-c1scc2occc12'\n",
      " 'c1[SiH2]c(cc1)-c1sc(-c2Cc(cc2)-c2cncc3nsnc23)c2[SiH2]ccc12']\n"
     ]
    }
   ],
   "source": [
    "print df_all.head(20).smiles.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 266)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 266)\n"
     ]
    }
   ],
   "source": [
    "#Drop the 'smiles' column\n",
    "df_all = df_all.drop(['smiles'], axis=1)\n",
    "lcols = df_all.columns.values.tolist()\n",
    "vals = df_all.values\n",
    "X_train = vals[:test_idx]\n",
    "X_test = vals[test_idx:]\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.609386\n",
      "Train data MSE is  0.0647608192365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.6f\" %LR.score(X_train,Y_train)\n",
    "LR_pred = LR.predict(X_train)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Random Forest Regressor MSE is 0.775009\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestRegressor()\n",
    "RF.fit(X_train[mask], Y_train[mask])\n",
    "\n",
    "print \"The Random Forest Regressor MSE is %0.6f\" %RF.score(X_train[~mask],Y_train[~mask])\n",
    "#RF_pred = RF.predict(X_train)\n",
    "#print \"Train data MSE is \",mean_squared_error(Y_train,RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_pred = RF.predict(X_test)\n",
    "write_to_file(\"RF_add.csv\", RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF score with added features: 0.18965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abscorr</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_025</th>\n",
       "      <td>0.419651</td>\n",
       "      <td>-0.419651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subgroup</th>\n",
       "      <td>0.374025</td>\n",
       "      <td>-0.374025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_218</th>\n",
       "      <td>0.363033</td>\n",
       "      <td>-0.363033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_102</th>\n",
       "      <td>0.363033</td>\n",
       "      <td>-0.363033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_119</th>\n",
       "      <td>0.351509</td>\n",
       "      <td>-0.351509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_001</th>\n",
       "      <td>0.275202</td>\n",
       "      <td>-0.275202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SiH2</th>\n",
       "      <td>0.273061</td>\n",
       "      <td>-0.273061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onelink</th>\n",
       "      <td>0.257443</td>\n",
       "      <td>-0.257443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doublelink</th>\n",
       "      <td>0.215819</td>\n",
       "      <td>-0.215819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_251</th>\n",
       "      <td>0.201831</td>\n",
       "      <td>-0.201831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big_c</th>\n",
       "      <td>0.167044</td>\n",
       "      <td>-0.167044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doublelinkC</th>\n",
       "      <td>0.141526</td>\n",
       "      <td>-0.141526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_187</th>\n",
       "      <td>0.140795</td>\n",
       "      <td>-0.140795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_126</th>\n",
       "      <td>0.097332</td>\n",
       "      <td>0.097332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_c</th>\n",
       "      <td>0.067834</td>\n",
       "      <td>-0.067834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_196</th>\n",
       "      <td>0.067323</td>\n",
       "      <td>-0.067323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_068</th>\n",
       "      <td>0.066528</td>\n",
       "      <td>-0.066528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_090</th>\n",
       "      <td>0.066134</td>\n",
       "      <td>-0.066134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_173</th>\n",
       "      <td>0.066045</td>\n",
       "      <td>-0.066045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_072</th>\n",
       "      <td>0.058528</td>\n",
       "      <td>-0.058528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_226</th>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.050456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_225</th>\n",
       "      <td>0.048919</td>\n",
       "      <td>-0.048919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnc</th>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.047662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_248</th>\n",
       "      <td>0.045301</td>\n",
       "      <td>0.045301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_176</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>-0.034318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>0.024305</td>\n",
       "      <td>0.024305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_243</th>\n",
       "      <td>0.019595</td>\n",
       "      <td>-0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_006</th>\n",
       "      <td>0.019595</td>\n",
       "      <td>-0.019595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_037</th>\n",
       "      <td>0.018839</td>\n",
       "      <td>-0.018839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_199</th>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.018540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              abscorr      corr\n",
       "feature                        \n",
       "feat_025     0.419651 -0.419651\n",
       "subgroup     0.374025 -0.374025\n",
       "feat_218     0.363033 -0.363033\n",
       "feat_102     0.363033 -0.363033\n",
       "feat_119     0.351509 -0.351509\n",
       "feat_001     0.275202 -0.275202\n",
       "SiH2         0.273061 -0.273061\n",
       "onelink      0.257443 -0.257443\n",
       "doublelink   0.215819 -0.215819\n",
       "feat_251     0.201831 -0.201831\n",
       "big_c        0.167044 -0.167044\n",
       "doublelinkC  0.141526 -0.141526\n",
       "feat_187     0.140795 -0.140795\n",
       "feat_126     0.097332  0.097332\n",
       "small_c      0.067834 -0.067834\n",
       "feat_196     0.067323 -0.067323\n",
       "feat_068     0.066528 -0.066528\n",
       "feat_090     0.066134 -0.066134\n",
       "feat_173     0.066045 -0.066045\n",
       "feat_072     0.058528 -0.058528\n",
       "feat_226     0.050456  0.050456\n",
       "feat_225     0.048919 -0.048919\n",
       "cnc          0.047662  0.047662\n",
       "feat_248     0.045301  0.045301\n",
       "feat_176     0.034318 -0.034318\n",
       "se           0.024305  0.024305\n",
       "feat_243     0.019595 -0.019595\n",
       "feat_006     0.019595 -0.019595\n",
       "feat_037     0.018839 -0.018839\n",
       "feat_199     0.018540  0.018540"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "correlations=[]\n",
    "for col in xrange(X_train.shape[1]):\n",
    "    r=pearsonr(X_train.T[col], Y_train)[0]\n",
    "    correlations.append(dict(feature=lcols[col],corr=r, abscorr=np.abs(r)))\n",
    "\n",
    "bpdf=pd.DataFrame(correlations).sort('abscorr', ascending=False)\n",
    "bpdf.set_index(['feature'], inplace=True)\n",
    "bpdf.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highcorr28=bpdf.head(28).index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced features and make transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.589331\n",
      "Train data MSE is  0.0680857959251\n"
     ]
    }
   ],
   "source": [
    "vals_rd = df_all[highcorr28].values\n",
    "X_train_rd = vals_rd[:test_idx]\n",
    "X_test_rd = vals_rd[test_idx:]\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train_rd, Y_train)\n",
    "\n",
    "print \"The Linear Regression Score is %0.6f\" %LR.score(X_train_rd,Y_train)\n",
    "LR_pred = LR.predict(X_train_rd)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.98655556e+00,  -4.01233053e-02,   6.38098239e-02,\n",
       "        -9.79686633e-02,  -1.28790029e-01,   6.81002031e-02,\n",
       "        -3.83428735e-01,  -2.36777524e-01,  -1.10642694e-03,\n",
       "         4.37832522e-03,  -2.71678918e-03,   2.39866315e-03,\n",
       "         7.00738559e-03,   1.47764281e-02,   1.44874902e-02,\n",
       "         2.09820989e-02,  -2.68229481e-02,   8.40889733e-03,\n",
       "         5.78146597e-03,   9.06195361e-03,  -2.63600702e-02,\n",
       "        -4.57501996e-02,  -1.15381035e-02,  -2.37111953e-02,\n",
       "        -1.46043573e-02,   6.91448277e-02,   1.07203060e-01,\n",
       "        -1.13311935e-01,  -4.40287882e-02])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check interaction terms degrees of polynomial.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "model = Pipeline([('poly', PolynomialFeatures(interaction_only=True)),\\\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "model = model.fit(X_train_rd, Y_train)\n",
    "model.named_steps['linear'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear Regression Score is 0.354722\n",
      "Train data MSE is  0.106982221276\n"
     ]
    }
   ],
   "source": [
    "print \"The Linear Regression Score is %0.6f\" %model.score(X_train_rd,Y_train)\n",
    "model_pred = model.predict(X_train_rd)\n",
    "print \"Train data MSE is \",mean_squared_error(Y_train,model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "n_folds=5\n",
    "results=[]\n",
    "hypothesisresults=[]\n",
    "for train, test in KFold(X_train.shape[0], n_folds): # split data into train/test groups, 4 times\n",
    "    model = Pipeline([('poly', PolynomialFeatures(interaction_only=True)),\\\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "    model = model.fit(X_train_rd[train], Y_train[train])\n",
    "    hypothesisresults.append(mean_squared_error(Y_train[test], model.predict(X_train_rd[test]))) \n",
    "    # evaluate score function on held-out data\n",
    "    results.append((np.mean(hypothesisresults), np.min(hypothesisresults), np.max(hypothesisresults))) # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.078526002114524332,\n",
       " 301280271342074.81,\n",
       " 0.078506093482369019,\n",
       " 0.078563148633583393,\n",
       " 0.078906159690809705]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesisresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([('poly', PolynomialFeatures(interaction_only=True)),\\\n",
    "                  ('linear', LinearRegression(fit_intercept=False))])\n",
    "\n",
    "model = model.fit(X_train_rd, Y_train)\n",
    "\n",
    "X_test_rd=df_test[highcorr28].values\n",
    "PolyRD_pred=model.predict(X_test_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"ployLinReg.csv\", PolyRD_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this submission:\n",
    "\n",
    "The Kaggle score is 0.27962, while the Baseline Linear Regression score is 0.29846.\n",
    "\n",
    "The CLF score is 0.526392, while the Baseline Linear Regression score is 0.461."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge/Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def cv_optimize(clf,parameters,X,y,n_folds,score_func=None):\n",
    "    if score_func:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    fitmodel.fit(X,y)\n",
    "    print \"BEST\", fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_\n",
    "    best = fitmodel.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_regress(clf, parameters,X,y,mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    \n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.5f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.5f\" % (test_accuracy)\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(X_train.shape[0]), train_size=0.7)\n",
    "mask=np.ones(X_train.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha': 10.0} -0.0647948743583 [mean: -0.06480, std: 0.00034, params: {'alpha': 0.001}, mean: -0.06480, std: 0.00034, params: {'alpha': 0.01}, mean: -0.06480, std: 0.00034, params: {'alpha': 0.1}, mean: -0.06480, std: 0.00034, params: {'alpha': 1.0}, mean: -0.06479, std: 0.00034, params: {'alpha': 10.0}, mean: -0.06480, std: 0.00033, params: {'alpha': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.60934\n",
      "Accuracy on test data:     0.60947\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge, Xtrain, ytrain, Xtest, ytest = do_regress(Ridge(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train, Y_train,mask=mask,score_func=\"mean_squared_error\",n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonzero(clf):\n",
    "    featuremask=(clf.coef_ !=0.0)\n",
    "    return pd.DataFrame(dict(feature=lcols, coef=clf.coef_, abscoef=np.abs(clf.coef_)))[featuremask].sort('abscoef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "ridge_importances=nonzero(ridge)\n",
    "ridge_importances.set_index(\"feature\", inplace=True)\n",
    "ridgeRD=ridge_importances.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha': 1.0} -0.0495843915231 [mean: -0.04958, std: 0.00017, params: {'alpha': 0.001}, mean: -0.04958, std: 0.00017, params: {'alpha': 0.01}, mean: -0.04958, std: 0.00017, params: {'alpha': 0.1}, mean: -0.04958, std: 0.00017, params: {'alpha': 1.0}, mean: -0.04959, std: 0.00017, params: {'alpha': 10.0}, mean: -0.04963, std: 0.00017, params: {'alpha': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.70126\n",
      "Accuracy on test data:     0.70147\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "X_train_rd = PolynomialFeatures(interaction_only=True).fit_transform(X_train_rd)\n",
    "ridge2, Xtrain, ytrain, Xtest, ytest = do_regress(Ridge(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train_rd, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vals_rd = df_all[ridgeRD].values\n",
    "X_train_rd_2 = vals_rd[:test_idx]\n",
    "X_test_rd_2 = vals_rd[test_idx:]\n",
    "\n",
    "X_train_rd_2=PolynomialFeatures(interaction_only=True).fit_transform(X_train_rd_2)\n",
    "ridge3, Xtrain, ytrain, Xtest, ytest = do_regress(Ridge(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train_rd_2, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge3 = ridge3.fit(X_train_rd_2, Y_train)\n",
    "X_test_rd_2=df_test[ridgeRD].values\n",
    "X_test_rd_2=PolynomialFeatures(interaction_only=True).fit_transform(X_test_rd_2)\n",
    "\n",
    "RidgeRD_pred=ridge3.predict(X_test_rd_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"ridgeRD.csv\", RidgeRD_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle score is 0.27941, while the Baseline Linear Regression score is 0.29846.\n",
    "\n",
    "The CLF score is 0.52659, while the Baseline Linear Regression score is 0.461.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abscorr</th>\n",
       "      <th>corr</th>\n",
       "      <th>abscoef</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_119</th>\n",
       "      <td>0.351509</td>\n",
       "      <td>-0.351509</td>\n",
       "      <td>0.431353</td>\n",
       "      <td>-0.431353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_044</th>\n",
       "      <td>0.011375</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>0.326316</td>\n",
       "      <td>0.326316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_251</th>\n",
       "      <td>0.201831</td>\n",
       "      <td>-0.201831</td>\n",
       "      <td>0.317880</td>\n",
       "      <td>-0.317880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_196</th>\n",
       "      <td>0.067323</td>\n",
       "      <td>-0.067323</td>\n",
       "      <td>0.310882</td>\n",
       "      <td>-0.310882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_069</th>\n",
       "      <td>0.016855</td>\n",
       "      <td>-0.016855</td>\n",
       "      <td>0.287012</td>\n",
       "      <td>-0.287012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_037</th>\n",
       "      <td>0.018839</td>\n",
       "      <td>-0.018839</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>0.223714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_068</th>\n",
       "      <td>0.066528</td>\n",
       "      <td>-0.066528</td>\n",
       "      <td>0.220960</td>\n",
       "      <td>-0.220960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_102</th>\n",
       "      <td>0.363033</td>\n",
       "      <td>-0.363033</td>\n",
       "      <td>0.196895</td>\n",
       "      <td>-0.196895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_218</th>\n",
       "      <td>0.363033</td>\n",
       "      <td>-0.363033</td>\n",
       "      <td>0.196895</td>\n",
       "      <td>-0.196895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_208</th>\n",
       "      <td>0.006035</td>\n",
       "      <td>-0.006035</td>\n",
       "      <td>0.189691</td>\n",
       "      <td>0.189691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_007</th>\n",
       "      <td>0.002430</td>\n",
       "      <td>-0.002430</td>\n",
       "      <td>0.183426</td>\n",
       "      <td>0.183426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_226</th>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.141252</td>\n",
       "      <td>0.141252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_225</th>\n",
       "      <td>0.048919</td>\n",
       "      <td>-0.048919</td>\n",
       "      <td>0.137497</td>\n",
       "      <td>-0.137497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_005</th>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.104084</td>\n",
       "      <td>0.104084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_090</th>\n",
       "      <td>0.066134</td>\n",
       "      <td>-0.066134</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>-0.094241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_132</th>\n",
       "      <td>0.002605</td>\n",
       "      <td>-0.002605</td>\n",
       "      <td>0.093890</td>\n",
       "      <td>-0.093890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_199</th>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.074262</td>\n",
       "      <td>0.074262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_200</th>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.074262</td>\n",
       "      <td>0.074262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_252</th>\n",
       "      <td>0.004816</td>\n",
       "      <td>-0.004816</td>\n",
       "      <td>0.073903</td>\n",
       "      <td>-0.073903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_248</th>\n",
       "      <td>0.045301</td>\n",
       "      <td>0.045301</td>\n",
       "      <td>0.071825</td>\n",
       "      <td>-0.071825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_187</th>\n",
       "      <td>0.140795</td>\n",
       "      <td>-0.140795</td>\n",
       "      <td>0.065947</td>\n",
       "      <td>-0.065947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_087</th>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>-0.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_025</th>\n",
       "      <td>0.419651</td>\n",
       "      <td>-0.419651</td>\n",
       "      <td>0.060581</td>\n",
       "      <td>-0.060581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_173</th>\n",
       "      <td>0.066045</td>\n",
       "      <td>-0.066045</td>\n",
       "      <td>0.039116</td>\n",
       "      <td>0.039116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_123</th>\n",
       "      <td>0.018079</td>\n",
       "      <td>-0.018079</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>-0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_001</th>\n",
       "      <td>0.275202</td>\n",
       "      <td>-0.275202</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>0.022954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_176</th>\n",
       "      <td>0.034318</td>\n",
       "      <td>-0.034318</td>\n",
       "      <td>0.021462</td>\n",
       "      <td>-0.021462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_126</th>\n",
       "      <td>0.097332</td>\n",
       "      <td>0.097332</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.018667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_072</th>\n",
       "      <td>0.058528</td>\n",
       "      <td>-0.058528</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>-0.018265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_243</th>\n",
       "      <td>0.019595</td>\n",
       "      <td>-0.019595</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_006</th>\n",
       "      <td>0.019595</td>\n",
       "      <td>-0.019595</td>\n",
       "      <td>0.007152</td>\n",
       "      <td>0.007152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           abscorr      corr   abscoef      coef\n",
       "feature                                         \n",
       "feat_119  0.351509 -0.351509  0.431353 -0.431353\n",
       "feat_044  0.011375 -0.011375  0.326316  0.326316\n",
       "feat_251  0.201831 -0.201831  0.317880 -0.317880\n",
       "feat_196  0.067323 -0.067323  0.310882 -0.310882\n",
       "feat_069  0.016855 -0.016855  0.287012 -0.287012\n",
       "feat_037  0.018839 -0.018839  0.223714  0.223714\n",
       "feat_068  0.066528 -0.066528  0.220960 -0.220960\n",
       "feat_102  0.363033 -0.363033  0.196895 -0.196895\n",
       "feat_218  0.363033 -0.363033  0.196895 -0.196895\n",
       "feat_208  0.006035 -0.006035  0.189691  0.189691\n",
       "feat_007  0.002430 -0.002430  0.183426  0.183426\n",
       "feat_226  0.050456  0.050456  0.141252  0.141252\n",
       "feat_225  0.048919 -0.048919  0.137497 -0.137497\n",
       "feat_005  0.001685  0.001685  0.104084  0.104084\n",
       "feat_090  0.066134 -0.066134  0.094241 -0.094241\n",
       "feat_132  0.002605 -0.002605  0.093890 -0.093890\n",
       "feat_199  0.018540  0.018540  0.074262  0.074262\n",
       "feat_200  0.018540  0.018540  0.074262  0.074262\n",
       "feat_252  0.004816 -0.004816  0.073903 -0.073903\n",
       "feat_248  0.045301  0.045301  0.071825 -0.071825\n",
       "feat_187  0.140795 -0.140795  0.065947 -0.065947\n",
       "feat_087  0.004644  0.004644  0.062000 -0.062000\n",
       "feat_025  0.419651 -0.419651  0.060581 -0.060581\n",
       "feat_173  0.066045 -0.066045  0.039116  0.039116\n",
       "feat_123  0.018079 -0.018079  0.030200 -0.030200\n",
       "feat_001  0.275202 -0.275202  0.022954  0.022954\n",
       "feat_176  0.034318 -0.034318  0.021462 -0.021462\n",
       "feat_126  0.097332  0.097332  0.018667  0.018667\n",
       "feat_072  0.058528 -0.058528  0.018265 -0.018265\n",
       "feat_243  0.019595 -0.019595  0.007152  0.007152\n",
       "feat_006  0.019595 -0.019595  0.007152  0.007152"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge important features and select the few important features...\n",
    "\n",
    "features=pd.concat([bpdf, ridge_importances], axis=1,join='inner')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'alpha': 0.001} -0.0659418048612 [mean: -0.06594, std: 0.00035, params: {'alpha': 0.001}, mean: -0.07582, std: 0.00033, params: {'alpha': 0.01}, mean: -0.15255, std: 0.00067, params: {'alpha': 0.1}, mean: -0.16583, std: 0.00067, params: {'alpha': 1.0}, mean: -0.16583, std: 0.00067, params: {'alpha': 10.0}, mean: -0.16583, std: 0.00067, params: {'alpha': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.60239\n",
      "Accuracy on test data:     0.60263\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso, Xtrain, ytrain, Xtest, ytest = do_regress(Lasso(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso, Xtrain, ytrain, Xtest, ytest = do_regress(Lasso(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train_rd, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso, Xtrain, ytrain, Xtest, ytest = do_regress(Lasso(), {\"alpha\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
    "                                                    X_train, Y_train,mask=mask,score_func=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=0.958, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bayesian Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "br = BayesianRidge(n_iter=300, tol=0.001, alpha_1=1.916/2)\n",
    "br.fit(X_train_rd,Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52641565815850599"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br.score(X_train_rd,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
